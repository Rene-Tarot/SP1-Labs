{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson4-gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpwTxfsGN5Qj"
      },
      "source": [
        "# **Copyright Information**\n",
        "\n",
        "####Copyright David GÃ¼ndisch\n",
        "#####El cÃ³digo original de este tutorial pertenece a David GÃ¼ndisch. Este cÃ³digo fue modificado agregando comentarios, explicaciones e imÃ¡genes para ser una prÃ¡ctica interactiva educativa.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVgwmGIau0AA",
        "outputId": "4415139a-e98c-4f3b-c47b-8700247d37f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tHDd2Aye8zf"
      },
      "source": [
        "### **Laboratorio 4: Redes Generativas Adversariales**\n",
        "En este laboratorio crearemos una Red Generativa Adversarial para generar nuevas imÃ¡genes de dÃ­gitos, similares a los dÃ­gitos del dataset MNIST.\n",
        "\n",
        "**Nota: recuerde activar la conexiÃ³n entre Google Colab y Google Drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt4Byq00Z0Nt"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only works in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJf_oqFYZ4Xw"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl0V7Eedu7Yt"
      },
      "source": [
        "Las Redes Generativas Adversariales son una forma de generar un modelo utilizando dos redes neurales que compiten una con otra.\n",
        "\n",
        "El **generador** convierte ruido en una imitaciÃ³n de los datos intentando engaÃ±ar al discriminador.\n",
        "\n",
        "EL **discriminador** intenta identificar los datos reales de los datos falsos creados por el generador.\n",
        "\n",
        "El generador recibe como entrada ruido aleatorio. Solamente el discriminador tiene acceso a los datos de entrenamiento para propÃ³sitos de clasificaciÃ³n.\n",
        "El generador mejora el resultado de su salida solamente utilizando la retroalimentaciÃ³n obtenida del discriminador.\n",
        "\n",
        "![texto alternativo](https://www.pngitem.com/pimgs/m/96-965914_a-short-introduction-to-generative-adversarial-networks-generative.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzMXgUhbu0V2"
      },
      "source": [
        "La clase GAN() contiene los mÃ©todos necesarios para construir nuestra red y entrenarla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Od-PHQZ6Qv"
      },
      "source": [
        "class GAN():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        \n",
        "        '''TODO: Especifique la dimensiÃ³n del espacio latente e.g. 100'''\n",
        "        self.latent_dim = 100\n",
        "        '''TODO: Especifique el optimizador que minimiza la funciÃ³n de perdida'''\n",
        "        optimizer = Adam()\n",
        "        \n",
        "        ### Discriminador de la GAN\n",
        "        self.discriminator = self.build_discriminator()\n",
        "\n",
        "        '''TODO: Coloque la funciÃ³n de perdida y la mÃ©trica correcta para el discriminador, ponga atenciÃ³n al trabajo\n",
        "        que estÃ¡ realizando el discriminador. e.g. clasificaciÃ³n multiclase, clasificaciÃ³n binaria, regresiÃ³n.'''\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "        \n",
        "        ### Generador de la GAN\n",
        "        self.generator = self.build_generator()\n",
        "        '''TODO: z es la entrada hacia el generador (vector 1D de ruido). Indique la dimensiÃ³n de entrada correcta para z.'''\n",
        "        #????\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        \n",
        "        '''TODO: el generador recibe ruido como entrada y devuelve una imagen'''\n",
        "        img = self.generator(z)\n",
        "        \n",
        "        '''TODO: No deseamos que la gradiente se propague hacia el discriminador, solamente deseamos propagar las gradientes\n",
        "        hacia el generador'''\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        '''TODO: El discriminador recibe la imagen creada por el generador y nos indica si la imagen es verdadera o falsa'''\n",
        "        validity = self.discriminator(img)\n",
        "        \n",
        "        '''TODO': Creamos un modelo con el generador y el discriminador unidos, especifique la entrada para el modelo completo\n",
        "        y la salida correspondiente. '''\n",
        "        self.combined = Model(inputs= z, outputs= validity)\n",
        "        \n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "        ### Este mÃ©todo construye la parte del generador de la GAN\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(256, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        \n",
        "        '''TODO: Agregue una capa totalmente conectada con una funciÃ³n de activaciÃ³n LeakyReLU y BatchNormalization.\n",
        "           Agregue una nueva capa totalmente conectada adicional con funciÃ³n de activaciÃ³n LeakyReLU y BatchNormalization\n",
        "           Recuerde que iniciamos nuestra entrada al generador con la dimensiÃ³n del espacio latente e.g. 100, debemos ir\n",
        "           aumentando las dimensiones de forma similar a la estructura utilizada en la secciÃ³n 'decoder' en un autoencoder.\n",
        "           Sabiendo esto debe indicar los valores correctos para la cantidad de salidas en cada capa densa.'''\n",
        "        \n",
        "        '''TODO: capa 1'''\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        '''TODO: capa 2'''\n",
        "        model.add(Dense(1024))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        \n",
        "        ### La penÃºltima capa del generador es un vector 1D con dimensiÃ³n ancho_imagen x alto_imagen e.g.784\n",
        "        \n",
        "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
        "        \n",
        "        '''TODO: Una imagen de un dÃ­gito de MNIST es un objeto 2D, nuestra capa anterior es 1D, debemos pasar de 1D (784,) \n",
        "        a 2D (28,28) utilizando Reshape(new_size)'''\n",
        "        model.add(Reshape(self.img_shape))\n",
        "        \n",
        "        model.summary()\n",
        "        \n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "        \n",
        "        '''TODO': La funciÃ³n build_generator() devuelve solamente la red neural que corresponde a la parte del generador.\n",
        "            Recuerde lo que recibe el generador como entrada y que entrega en la salida.'''\n",
        "        return Model(inputs=noise, outputs=img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "    \n",
        "        model = Sequential()\n",
        "        ### El discriminador es un clasificador, este clasificador no utiliza CNN, es un clasificador con una FCN, su entrada es un vector 1D\n",
        "        model.add(Flatten(input_shape=self.img_shape))\n",
        "        \n",
        "        '''TODO: agregue dos capas densas con funciÃ³n de activaciÃ³n LeakyRelu'''\n",
        "        '''TODO: capa 1'''\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        '''TODO: capa 2'''\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        \n",
        "        '''TODO: el discriminador es un clasificador. Â¿Es un clasificador binario o debe clasificar mas de 2 clases?'''\n",
        "        \n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        \n",
        "        model.summary()\n",
        "        \n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "        \n",
        "        '''TODO': La funciÃ³n build_discriminator() devuelve solamente la red neural que corresponde a la parte del discriminador.\n",
        "           Recuerde lo que recibe el discriminador como entrada y que entrega en la salida.'''\n",
        "        return Model(inputs=img, outputs=validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "        ### MÃ©todo de entrenamiento de la GAN\n",
        "        \n",
        "        ### Se carga el dataset MNIST\n",
        "        (X_train, _), (_, _) = mnist.load_data()\n",
        "        \n",
        "        ### Escalamos el valor de los pixels al rango (-1,1)\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        \n",
        "        ### El dataset contiene 60k imÃ¡genes de 28x28 pixels, los caracteres son blanco y negro, por lo tanto usualmente \n",
        "        ### el shape del dataset no incluye canales. Expandimos nuestro dataset para indicar que solo tenemos 1 canal.\n",
        "        ### dataset shape  = (60000, 28, 28) -> (60000, 28, 28, 1)\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "        \n",
        "        ### Etiquetas (labels) para enviar al discriminador para las imÃ¡genes verdaderas y falsas. \n",
        "        ### imagen verdadera = 1 , imagen falsa = 0\n",
        "        ### valid.shape = (132, 1)   \n",
        "        ### fake.shape(132,1)\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        ### Proceso iterativo de entrenamiento del modelo\n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            ### Se carga un batch para entrenamiento\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "            \n",
        "            \n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            '''TODO: train_on_batch ejecuta una Ãºnica actualizaciÃ³n de gradiente con un batch de datos\n",
        "                \n",
        "               Entrenamos el generador en el modelo combinado, utilizando la retroalimentaciÃ³n\n",
        "               que nos da el discriminador.         \n",
        "               Realizamos foward_pass a travÃ©s del modelo combinado generador + discriminador. \n",
        "               pero en backward_pass solo propagamos la gradiente hacia el generador, logramos esto \n",
        "               porque recuerde que anteriormente indicamos que los pesos del discriminador \n",
        "               serÃ¡n no entrenables en el modelo combinado.\n",
        "               Indicaremos que las etiquetas(labels) para las imÃ¡genes creadas por el generador \n",
        "               seran verdaderas e.g 1. (porque deseamos hacer pasarlas por reales)\n",
        "             \n",
        "               En un una iteraciÃ³n el discriminador estÃ¡ entrenado para distinguir \n",
        "               imÃ¡genes verdaderas y falsas.\n",
        "               El generador a partir de ruido genera una imagen. En este momento\n",
        "               no sabemos si esta imagen es lo suficiente buena para pasar por real, pero queremos hacerla \n",
        "               pasar por real, por lo tanto como etiqueta indicaremos que esta imagen es verdadera e.g 1.\n",
        "               Deseamos que el generador se acerque lo mas posible a generar imÃ¡genes reales.\n",
        "               Posteriormente esta imagen pasa al discriminador a travÃ©s del modelo combinado y el \n",
        "               discriminador podrÃ¡ decirnos si es verdadera o falsa.\n",
        "               Utilizando esa informaciÃ³n que nos da el discriminador, modificaremos los pesos del generador \n",
        "               para que la prÃ³xima iteraciÃ³n podamos acercarnos mÃ¡s a engaÃ±ar al discriminador.'''\n",
        "            \n",
        "\n",
        "            g_loss = self.combined.train_on_batch(x=noise, y=valid)\n",
        "\n",
        "            '''TODO: Posteriormente de haber realizado una actualizaciÃ³n de los pesos del generador, generaremos un batch de\n",
        "               imÃ¡genes (falsas) a partir de ruido.''' \n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            \n",
        "            '''TODO: Entrenamos al discriminador para que aprenda a clasificar \n",
        "               correctamente imÃ¡genes verdaderas. Para esto debemos enviarle ejemplos\n",
        "               de imÃ¡genes reales. Las imÃ¡genes verdaderas son las imÃ¡genes\n",
        "               que se obtienen del dataset MNIST. Debemos indicarle al discriminador \n",
        "               que estas imÃ¡genes son verdaderas, esto lo hacemos asignando a cada imagen una etiqueta\n",
        "               verdadera e.g 1'''\n",
        "            d_loss_real = self.discriminator.train_on_batch(x=imgs, y=valid)\n",
        "\n",
        "            '''TODO: Entrenamos al discriminador para que aprenda a identificar\n",
        "               correctamente imÃ¡genes falsas. Para esto debemos enviarle ejemplos\n",
        "               de imÃ¡genes falsas. Las imÃ¡genes falsas son las imÃ¡genes\n",
        "               que se obtienen del generador. Debemos indicarle al discriminador \n",
        "               que estas imÃ¡genes son falsas, esto lo hacemos asignando a cada imagen una etiqueta\n",
        "               falsa e.g 0'''\n",
        "            d_loss_fake = self.discriminator.train_on_batch(x=gen_imgs, y=fake)\n",
        "\n",
        "            ### valor de perdida del discriminador\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "            \n",
        "            if epoch % 50 == 0:\n",
        "                print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        ### FunciÃ³n que crea un archivo .png con ejemplos de imÃ¡genes nuevas generadas por\n",
        "        ### el generador\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "                axs[i, j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"/content/drive/My Drive/%d.png\" % epoch)\n",
        "        plt.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r68GIhOuUiHM",
        "outputId": "4f2798d4-5a22-489c-b016-ce23426a6a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### Al finalizar el entrenamiento vea las imÃ¡genes resultantes \n",
        "### creadas por el generador a travÃ©s de cada iteraciÃ³n en su directorio de Google Drive.\n",
        "\n",
        "gan = GAN()\n",
        "gan.train(epochs=100000, batch_size=132, sample_interval=10000)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "0 [D loss: 0.724661, acc.: 41.29%] [G loss: 0.663359]\n",
            "50 [D loss: 0.007447, acc.: 99.62%] [G loss: 12.198501]\n",
            "100 [D loss: 0.009058, acc.: 100.00%] [G loss: 13.123095]\n",
            "150 [D loss: 0.001579, acc.: 100.00%] [G loss: 13.229207]\n",
            "200 [D loss: 0.697867, acc.: 85.98%] [G loss: 39.738098]\n",
            "250 [D loss: 0.002338, acc.: 100.00%] [G loss: 16.133619]\n",
            "300 [D loss: 0.001700, acc.: 100.00%] [G loss: 8.098697]\n",
            "350 [D loss: 0.007311, acc.: 99.62%] [G loss: 30.631920]\n",
            "400 [D loss: 0.005605, acc.: 99.62%] [G loss: 16.936403]\n",
            "450 [D loss: 0.000390, acc.: 100.00%] [G loss: 20.768503]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d4363da30bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m132\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-c0113084c15b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    168\u001b[0m             '''TODO: Posteriormente de haber realizado una actualizaciÃ³n de los pesos del generador, generaremos un batch de\n\u001b[1;32m    169\u001b[0m                imÃ¡genes (falsas) a partir de ruido.''' \n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}